---
title: "lab_11"
author: "Molecule Jongwilai"
date: "2024-11-13"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## You will need

-   Our usual libraries for working with data, including dates and column names, plus rvest.

## Load libraries and establish settings

**Task** Create a codeblock and load appropriate packages and settings for this lab.

```{r}
library(rvest)
library(tidyverse)
library(janitor)
library(lubridate)
```
Let's get to scraping. We'll be working on collecting information about Maryland election results, and then we'll grab some congressional press releases. For Maryland races, we'll focus on Board of Education races using this CNS story as a guide: https://cnsmaryland.org/2024/11/08/md-conservatives-make-gains-in-school-board-races/. You should read it.

## Questions

**Q1**. Write code to scrape the table of unofficial results from Frederick County's Board of Education races (https://elections.maryland.gov/elections/2024/general_Results/gen_results_2024_by_county_11.html), producing a dataframe that contains the results of that race for each candidate and removing the total. You'll need to identify which table on the page contains the BOE results. All numbers should actually be numbers, including the percentage. Then make a bar chart of the results, noting that the top 3 candidates win.

**A1** Table 9th contains BOE results.

```{r}
#Assign url as variable 
board_of_election_url <- "https://elections.maryland.gov/elections/2024/general_Results/gen_results_2024_by_county_11.html"

#Read in the HTML 
board_of_election_result <- board_of_election_url |>
  read_html() |>
  html_table()

#Check all the tables
board_of_election_result

#Choose table of BOE 
board_of_election_result <- board_of_election_result[[9]]
board_of_election_result

#Clean the dataframe
board_of_election_result <- board_of_election_result |>
  clean_names() |>
  slice(-9) |>
  mutate(early_voting = as.numeric(gsub(",","", early_voting))) |>
  mutate(election_day = as.numeric(gsub(",","", election_day))) |>
  mutate(mail_in_ballot = as.numeric(gsub(",","", mail_in_ballot))) |>
  mutate(provisional = as.numeric(provisional)) |>
  mutate(total = as.numeric(gsub(",","", total))) |>
  mutate(percentage = as.numeric(gsub("%","", percentage)))

#Make Bar Chart 
board_of_election_result |>
  ggplot() +
  geom_bar(aes(x=reorder(name, total), weight=total)) +
  coord_flip() +
  theme_minimal() +
  labs(
    title="Brennan, Monier, Black Lead in Frederick's Board of Election Races",
    y = "Total of Votes",
    x = "Candidates",
    caption = "This result is unofficial. Three candidates with most votes win election.") 
```

**Q2** Next, let's scrape the list of press releases from Maryland's Office of the Public Defender, <https://osp.maryland.gov/category/press-releases/>. This isn't a table, so you'll need to use `html_elements()` and your browser's inspector and do some clean up on the results. The result should be a dataframe with three columns: title, url and date. HINT: you can extract the date from the title using lubridate OR you can use the `separate` function.

You should have 10 releases when finished, not 20.

Then, write code that finds the most recent release with the word "Campaign" in the title. What election does it refer to?

**A2** This release refers to John King's campaign for the governor's election. 

```{r}
#Extract title and url
#Assign html
public_defender_url <- "https://osp.maryland.gov/category/press-releases/"
#Read html
press_release <- public_defender_url |>
  read_html()
#Grab the elements
press_release <- press_release |> html_elements("h2 a")
#Make dataframe
title_url <- tibble(
  title = press_release %>% html_attr("title"),
  url = press_release %>% html_attr("href")
)
#Just try different method
title_url_2 <- tibble(
  title = press_release %>% html_text(trim = TRUE),
  url = press_release %>% html_attr("href")
)

#Extract date
#Assign html
time <- public_defender_url |>
  read_html()
#Grab the elements
time <- time |> 
  html_elements("time")
#Make dataframe
date <- tibble(
  date = time %>% html_text(trim = TRUE)
) 

#Merge the columns
library(dplyr)
title_url_date <- bind_cols(title_url, date)

#Clean the dataframe
title_url_date <- title_url_date |>
  separate(title, c("x", "title"), sep=': ') |>
  select(-1) |>
  mutate(date = mdy(date))

#Find the release with word "Campaign"
title_url_date |>
  filter(str_detect(title, "Campaign"))
```

**Q3** Sen. Ben Cardin, D-Maryland, has posted hundreds of press releases at <https://www.cardin.senate.gov/?post_type=press-releases>. It would be great to have all of them in a dataframe that has the following columns: date, title and url.

To do this, you will need to scrape the page's html and save that to a variable, and *then* extract the dates, titles and urls into *separate* dataframes using html_elements(). We turn a list into a dataframe using `as_tibble()`.

At the end, you'll have three dataframes that you want to combine into a single dataframe. When we want to combine the rows of identical dataframes, we used `bind_rows()`. If you were combining columns instead of rows, there's a similar function. Use it to put all of the dataframes together into a single one. You are combining columns, not rows.

When you're done, rename the columns so they make sense, then make sure the date column is an actual date.

Finally, tell me what questions you could ask of this data, and what other information about it would be useful to have. Be creative.

**A3** Questions I would want to know from this data is how many times each Maryland county was mentioned in the press releases. This could be interesting as it may imply how much Sen. Ben Cardin focuses on issues in each county. What is the county that was mentioned in the press release the most and which county is the least? We may also need the column that contains the lead paragraph of each press release which we also can scrape from the site to roughly know more context of press releases that mention each county.    

```{r}
#Assign and read HTML 
ben_cardin_url <- "https://www.cardin.senate.gov/?post_type=press-releases"
ben_cardin_html <- ben_cardin_url |>
  read_html()

#Extract dates
#Grab element
ben_cardin_html_dates <- ben_cardin_html |>
  html_elements("h5")
#Make dataframe
ben_cardin_dates <- tibble(
  date = ben_cardin_html_dates %>% html_text(trim=TRUE)
)
#Clean Data
ben_cardin_dates <- ben_cardin_dates |>
  mutate(date = mdy(date))

#Extract titles
#Grab element
ben_cardin_html_titles <- ben_cardin_html |>
  html_elements("h3 a")
#Make dataframe
ben_cardin_titles <- tibble(
  title = ben_cardin_html_titles %>% html_text(trim=TRUE)
)

#Extract urls
#Grab element
ben_cardin_html_urls <- ben_cardin_html |>
  html_elements("h3 a")
#Make dataframe
ben_cardin_urls <- tibble(
  url = ben_cardin_html_urls %>% html_attr("href")
)

#Merge the columns
ben_cardin_dates_titles_urls <- bind_cols(ben_cardin_dates, ben_cardin_titles, ben_cardin_urls)

```